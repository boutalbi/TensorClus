### Dataset description
#### DBLP1, DBLP2, and PubMed-Diabetes
We use three text datasets DBLP1, DBLP2 and PubMed Diabetes https://linqs.soe.ucsc.edu/data to highlight the objective of the proposed algorithm. DBLP1 and DBLP2 are constructed from https://aminer.org/citation, by selecting three journals for each one which represent the true partition.
The selected journals for DBLP1 are SIGMOD, STOC, and SIGIR. The journals selected for DBLP2 are Discrete Applied Mathematics, IEEE software, and SIGIR. For PubMed Diabetes dataset the papers are categorized into three types, the first one deals with Diabetes mellitus of type 1, the second with Diabetes mellitus of type 2, and the third with Diabetes mellitus Experimental.

From these different datasets, we construct the following adjacency matrices: 

- Co-terms matrix on the title: each cell represents the number of  times that a term is present simultaneously in the title of a pair of papers. This matrice is computed using $\mathcal{T}\mathcal{T}^{T}$ where $\mathcal{T}$ is a binarized document-terms matrix.
- Co-terms matrix on the abstract: each cell represents the number of times that a pair of papers share a term extracting from abstract. We use the same process used in Co-terms Title matrix. 
- Co-authors matrix: each cell represents the number of common authors for a pair of papers. This matrice is computed using $\mathcal{A}\mathcal{A}^{T}$ where $\mathcal{A}$ is a binarized document-authors matrix.
- Citations matrix: is a binary data matrix where 1 indicates the presence of a citation between two papers. 

The constructed tensor $(Paper \times Paper \times Relation)$ for each dataset DBLP1, DBLP2 and  PubMed Diabetes has respectively size $(2223 \times 2223 \times 4)$, $(1949 \times 1949 \times 4)$, and $(4354 \times 4354 \times 4)$ and different rates of sparsity 0.93, 0.94, and 0.69 respectively.

#### Nus-Wide-8 dataset
It is a part of the Nus-Wide images dataset https://dl.acm.org/citation.cfm?id=1646452 extracted using Flickr API. This dataset is composed of eight topics, namely Animals, Persons, Plants, Snow, Street, Temple, Town, and Wedding. We constructed six graphs â€” the Co-tags graph, which is an adjacency matrix of common tags between images. As described in the previous paragraph for Co-terms matrix, we used a binary matrix images-tags $\calM$ to compute Co-tags matrix $\calH$ by $\calM\calM^{\top}$. Other graphs are also created based on extracted features from images. The followed process to build graph similarity based on six extracted features form images including 64-D Color Histogram (CH), 144-D Color Correlogram (CORR), 73-D Edge direction histogram (EDH), 128-D Wavelet texture (WT), 225-D block-wise color moments (CW55). The computed similarity matrices are converted to adjacency matrices by putting one if the similarity is higher than ninety-seven percent quantile and zero otherwise. 

#### Amazon-Products-10 dataset

It is a part of the Amazon-products dataset http://jmcauley.ucsd.edu/data/amazon/links.html, composed of product images. We consider ten product categories, namely Beauty, Digital music, Home and kitchen, Office products, Cell phones, Sports and outdoors, Health and personal care, Clothing-Shoes-Jewelry, Patio-garden, and Baby. We constructed seven graphs. The three first one Similarity LBP, Similarity Haralick and Similarity Gabor are constructed based on Low Rank Representation (LRR) method for three different features namely 256-D Local Binary Patterns (LBP), 216-D Haralick features  (considering distances $d= 1\ldots9$, orientations $\theta$ = [0, 45, 90, 135]) and 192-D Gabor features  (considering scales $\sigma = 1...4$, orientations $\theta$ = [0, 45, 90, 135]). The computed similarity matrices are converted to adjacency matrices by putting one if the similarity is higher than ninety-seven percent quantile and zero otherwise. \textit{Co-terms Title} and \textit{Co-terms Description} are adjacency matrices representing the co-terms between the title and description of products, respectively. Finally, Co-viewed and Co-purchased are adjacency matrices $\calY$, where $\calY_{ij}=1$ means that these two products are viewed (respectively purchased) simultaneously when users make a query.   